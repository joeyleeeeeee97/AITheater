# Design Document: `video_generator.py` - The AI Director

## 1. Role & Goal

The `video_generator.py` script serves as the final stage in the AI Avalon Gameplay Video Generator pipeline. Its primary role is that of an **"AI Director"** or **"Compositor"**.

The ultimate goal of this script is to programmatically and automatically synthesize all previously generated assets—the structured script, the narrated audio files, and static visual assets—into a single, cohesive, and polished video file (`avalon_game.mp4`). It must do so in a way that is visually clear, dramatically effective, and requires zero manual intervention.

## 2. Core Principles

*   **Data-Driven**: Every visual and auditory event in the final video must be driven by the data from `final_script.json` and `audio_metadata.json`. The code should contain rendering logic, not content.
*   **Highly Configurable**: All aesthetic and layout decisions (positions, colors, fonts, sizes) must be defined in an external configuration file (`layout.yaml`), not hardcoded. This allows for easy "reskinning" of the final video without touching the logic.
*   **Frame-Perfect Synchronization**: The timing of all visual cues (highlighting the speaker, showing subtitles) must be perfectly synchronized with the corresponding audio narration, down to the millisecond.

## 3. Technical Stack

*   **Primary Library**: **MoviePy**. This library is chosen for its powerful, intuitive, code-based approach to video composition. It allows for precise control over the timing, positioning, and layering of video clips, text, and audio.
*   **Configuration**: **PyYAML**. Used to parse the `layout.yaml` configuration file.

## 4. Input Assets

The script will require the following inputs to function:

1.  **`outputs/final_script.json`**: The master "shooting script" generated by the AI Screenwriter. It provides the content for subtitles (`summary`) and the mapping of events to players.
2.  **`outputs/audio_metadata.json`**: The "master timeline". It provides the precise duration of each audio clip and its file path, which dictates the timing of all visual events.
3.  **`outputs/generated_audio/`**: A directory containing all the individual `.mp3` voice-over files.
4.  **`assets/`**: A directory containing all static visual assets, such as:
    *   `background.png`: The main background image for the game.
    *   `player_avatars/`: A sub-directory containing images for each player (e.g., `player_0.png`, `player_1.png`).
    *   `fonts/`: A sub-directory for any custom fonts used.
5.  **`layout.yaml`**: The master configuration file defining all visual styles and positions.

## 5. Core Logic & Execution Flow

The script will execute in a sequential, layer-based composition flow.

### Step 1: Initialization & Asset Loading

*   The script starts by parsing `layout.yaml`, `final_script.json`, and `audio_metadata.json` into memory.
*   It calculates the `total_duration` of the video by summing the `duration_ms` of all clips in `audio_metadata.json`.

### Step 2: Base Scene Composition

*   A main `background_clip` is created from the background image, with its duration set to `total_duration`.
*   The script then iterates through the `player_positions` defined in `layout.yaml`. For each player, it creates a **default state** visual group:
    *   An `ImageClip` is created for the player's avatar.
    *   A `TextClip` is created for the player's model tag (e.g., "gpt-4o").
    *   These two clips are positioned relative to each other and then set to the player's master position on the screen.
*   All these default player visuals are composited together into a single `default_player_layer`. This layer is set to the `total_duration`.

### Step 3: Dynamic Overlay Layer Generation

This is the core loop of the program. The script iterates through the `audio_metadata.json` file. For each entry (representing a speech event), it generates a list of temporary "overlay" clips that will only appear during that speech's duration.

*   **Calculate Timing**: The `start_time` for the current event is calculated by summing the durations of all previous events. The `duration` is taken directly from the metadata.
*   **Generate Highlight Layer**:
    *   A new avatar `ImageClip` is created for the speaking player, but this time styled with the "speaking" state defined in `layout.yaml` (e.g., a golden border).
    *   This clip's `start` and `duration` are set to the calculated `start_time` and `duration`.
*   **Generate Summary (Subtitle) Layer**:
    *   The corresponding `summary` text is retrieved from `final_script.json` using the event index.
    *   A `TextClip` is created with this text, styled and positioned according to the `summary_box` configuration in `layout.yaml`.
    *   This clip's `start` and `duration` are also set to the calculated `start_time` and `duration`.
*   All generated overlay clips for all speech events are collected into a single list called `dynamic_layers`.

### Step 4: Audio Track Composition

*   The script iterates through `audio_metadata.json` again.
*   Each `.mp3` file is loaded as an `AudioFileClip`.
*   Each audio clip is set to start at its calculated `start_time`.
*   All audio clips are combined into a single audio track using `CompositeAudioClip`.

### Step 5: Final Assembly and Rendering

*   A final `CompositeVideoClip` is created. The list of clips provided to it will be:
    1.  The `background_clip`.
    2.  The `default_player_layer`.
    3.  **All** clips from the `dynamic_layers` list (unpacked).
*   MoviePy intelligently layers these clips, with later clips in the list appearing on top of earlier ones. The `start` and `duration` properties of each clip ensure they appear and disappear at the correct moments.
*   The composite audio track from Step 4 is attached to this final video clip using `.set_audio()`.
*   The final clip is rendered to a file using `.write_videofile()`.

## 6. Output

*   **`outputs/avalon_game.mp4`**: A high-resolution video file containing the fully composited and narrated gameplay.

This design ensures a robust, flexible, and fully automated system for transforming our game data into a professional-looking video.
